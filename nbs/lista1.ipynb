{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(*images: np.ndarray, titles: list[str] | None = None, columns: int = 2, scale: int = 5) -> None:\n",
    "    num_images = len(images)\n",
    "    \n",
    "    if titles is None:\n",
    "        titles = [f'Image {i+1}' for i in range(num_images)]\n",
    "    \n",
    "    rows = (num_images + columns - 1) // columns \n",
    "\n",
    "    fig, axes = plt.subplots(rows, columns, figsize=(scale * columns, scale * rows))\n",
    "    axes = np.array(axes).reshape(rows, columns)\n",
    "\n",
    "    for ax, img, title in zip(axes.flat, images, titles):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(title)\n",
    "\n",
    "    for i in range(num_images, rows * columns):\n",
    "        fig.delaxes(axes.flat[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def show_image(image: np.ndarray, title: str = None, dpi: int = 100) -> None:\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    figsize = (width / dpi, height / dpi)\n",
    "    \n",
    "    plt.figure(figsize=figsize, dpi=dpi)\n",
    "    plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
    "    plt.title(title if title else \"\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def get_black_and_white(img: np.ndarray) -> np.ndarray:\n",
    "    def rgb_to_grayscale(rgb: np.ndarray) -> np.uint8:\n",
    "        return 0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]\n",
    "    return np.apply_along_axis(rgb_to_grayscale, 2, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Abaixo estão implementadas as funções de:\n",
    "- Leitura e salvamento de imagens .ppm\n",
    "- Aplicação do filtro\n",
    "    - A função `filter_channel` aplica o filtro a apenas um dos canais (r, g ou b), ou seja, um vetor (n, m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ppm(ppm_path: str) -> np.ndarray:\n",
    "    with open(ppm_path, 'rb') as ppm:\n",
    "        header = ppm.readline().decode()\n",
    "        if header.strip() != 'P6':\n",
    "            raise Exception('Only Raw PPM file supported.')\n",
    "        \n",
    "        metadata_count = 0\n",
    "        metadata = []\n",
    "        while metadata_count < 2:\n",
    "            line = ppm.readline().decode()\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            \n",
    "            metadata.extend([int(v) for v in line.split(' ')])\n",
    "            metadata_count += 1\n",
    "            \n",
    "        width, height, maxval = metadata\n",
    "\n",
    "        if maxval > 255:\n",
    "            raise Exception('Only 8-bit images supported.')\n",
    "\n",
    "\n",
    "        return np.frombuffer(ppm.read(), dtype=np.uint8).reshape((height, width, 3))\n",
    "\n",
    "def save_ppm(ppm_image: np.ndarray, filename: str, foldername:str='./output') -> None:\n",
    "    folder = Path(foldername)\n",
    "    folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    filepath = folder / Path(filename)\n",
    "\n",
    "    ppm_image = np.clip(ppm_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    if len(ppm_image.shape) == 2:\n",
    "        header = 'P5'\n",
    "        height, width = ppm_image.shape\n",
    "    elif len(ppm_image.shape) == 3:\n",
    "        height, width, _ = ppm_image.shape\n",
    "        header = 'P6'\n",
    "    else:\n",
    "        raise ValueError(\"Image not supported!\")\n",
    "\n",
    "    maxval = 255\n",
    "\n",
    "    with open(filepath, 'wb') as ppm:\n",
    "        ppm.write(f\"{header}\\n\".encode('ascii'))\n",
    "        ppm.write(f\"{width} {height}\\n\".encode('ascii'))\n",
    "        ppm.write(f\"{maxval}\\n\".encode('ascii'))\n",
    "        ppm.write(ppm_image.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_channel(img_channel: np.ndarray, kernel_size: int, kernel: np.ndarray, normalize: bool = False) -> np.ndarray:\n",
    "    output = np.zeros(img_channel.shape, dtype=np.float64)\n",
    "    kernel = np.flip(kernel, axis=(0,1))\n",
    "    pad_size = kernel_size // 2\n",
    "\n",
    "    padded_img = np.pad(img_channel.astype(np.float64), pad_size, mode='constant')\n",
    "    height, width = padded_img.shape\n",
    "\n",
    "    for i in range(pad_size, height - pad_size):\n",
    "        for j in range(pad_size, width - pad_size):\n",
    "            chunk = padded_img[i - pad_size:i + pad_size + 1, j - pad_size:j + pad_size + 1]\n",
    "            output[i - pad_size, j - pad_size] = np.sum(chunk * kernel)\n",
    "\n",
    "    if normalize:\n",
    "        output = (output - np.min(output)) / (np.max(output) - np.min(output)) * 255\n",
    "    else:\n",
    "        output = np.clip(output, 0, 255)\n",
    "    \n",
    "    return output.astype(np.uint8)\n",
    "\n",
    "\n",
    "def apply_filter(img: np.ndarray, kernel_size: int, kernel: np.ndarray, normalize: bool = False) -> np.ndarray:\n",
    "    filtered_channels = []\n",
    "    for c in range(3):\n",
    "        filtered_channels.append(filter_channel(img[:, :, c], kernel_size, kernel, normalize))\n",
    "    \n",
    "    return np.stack(filtered_channels, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando função da questão 1 com filtro média\n",
    "img_path = '../ppm_images/west_1.ppm'\n",
    "img = read_ppm(img_path)\n",
    "\n",
    "n = 3\n",
    "mean_kernel = 1 / 9 * np.ones((n, n), dtype=np.float64)\n",
    "\n",
    "filtered = apply_filter(img, n, mean_kernel)\n",
    "show_images(img, filtered, titles=[\"Original\", \"Mean\"])\n",
    "save_ppm(filtered, 'mean.ppm', '../output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "Como filtro passa-alta, escolhi $I - Gauss$, sendo o kernel do filtro Gaussiano gerado pela função `get_gaussian_kernel` apresentada como resposta em uma [pergunta do stackoverflow](https://stackoverflow.com/questions/29731726/how-to-calculate-a-gaussian-kernel-matrix-efficiently-in-numpy). Optei por buscar uma função, já que o objetivo era gerar uma imagem filtrada para vários valores de $n$ e só havia encontrado kernels para a função gaussiana em tamanho 3x3 e 5x5.\n",
    "\n",
    "Como é possível ver abaixo, quanto maior é o tamanho do kernel ($n$) maior é o destaque dos detalhes, que são as regiões de alta frequência, ou seja, onde os pixels variam mais de intensidade/cor.\n",
    "\n",
    "Usei a normalização da imagem de saída da convolução para que o resultado ficasse mais próximo do apresentado no slide, com os tons de cinza. Também funcionaria sem a normalização, apenas usando o np.clip() entre 0 e 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identity_kernel(size: int) -> np.ndarray:\n",
    "    if size % 2 == 0:\n",
    "        raise Exception(\"Kernel must have an odd size.\")\n",
    "    if size <= 1:\n",
    "        raise Exception(\"Kernels must have size 3 or greated (and should be odd).\")\n",
    "\n",
    "    identity = np.zeros((size, size), dtype=np.float32)\n",
    "    identity[size//2, size//2] = 1\n",
    "    return identity\n",
    "\n",
    "# Referência: \n",
    "# https://stackoverflow.com/questions/29731726/how-to-calculate-a-gaussian-kernel-matrix-efficiently-in-numpy\n",
    "def get_gaussian_kernel(size=5, sigma=1) -> np.ndarray:\n",
    "    ax = np.linspace(-(size - 1) / 2.0, (size - 1) / 2.0, size)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sigma))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/mine/gandalf.ppm'\n",
    "img = read_ppm(img_path)\n",
    "\n",
    "images = []\n",
    "titles = []\n",
    "\n",
    "for n in [5, 9, 21]:\n",
    "    identity_kernel = get_identity_kernel(n)\n",
    "    gauss_kernel = get_gaussian_kernel(n, sigma=5)\n",
    "\n",
    "    highpass_kernel = identity_kernel - gauss_kernel\n",
    "    filtered = apply_filter(img, n, highpass_kernel, normalize=True)\n",
    "    images.append(filtered)\n",
    "    titles.append(f'n={n}')\n",
    "    save_ppm(filtered, f'highpass_{n}.ppm', '../output')\n",
    "\n",
    "show_images(*images, titles=titles, columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3\n",
    "\n",
    "Um exemplo de filtro que não pode ser aplicado via convolução seria o filtro mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_channel(img_channel: np.ndarray, kernel_size: int) -> np.ndarray:\n",
    "    output = np.zeros(img_channel.shape, dtype=np.float64)\n",
    "    pad_size = kernel_size // 2\n",
    "    padded_img = np.pad(img_channel.astype(np.float64), pad_size, mode='constant')\n",
    "    height, width = padded_img.shape\n",
    "\n",
    "    for i in range(pad_size, height - pad_size):\n",
    "        for j in range(pad_size, width - pad_size):\n",
    "            chunk = padded_img[i - pad_size:i + pad_size + 1, j - pad_size:j + pad_size + 1]\n",
    "            output[i - pad_size, j - pad_size] = np.median(chunk)\n",
    "\n",
    "    return np.clip(output, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def apply_median_filter(img: np.ndarray, filter_size: int) -> np.ndarray:\n",
    "    filtered_channels = []\n",
    "    for c in range(3):\n",
    "        filtered_channels.append(median_filter_channel(img[:, :, c], filter_size))\n",
    "    \n",
    "    return np.stack(filtered_channels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/mine/airplane.ppm'\n",
    "img = read_ppm(img_path)\n",
    "\n",
    "n = 7\n",
    "filtered = apply_median_filter(img, n)\n",
    "show_images(img, filtered, titles=[\"Original\", \"Median\"], scale=8)\n",
    "\n",
    "save_ppm(filtered, 'median.ppm', '../output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4\n",
    "\n",
    "Abaixo estão as funções utilizadas para obter a derivada de uma imagem usando os filtros de Sobel 3x3 e o para obter o Gradiente da imagem. Apesar de parecidas com as funções anteriores, possuem algumas diferenças, e.g., não é feito o clip dos valores da imagem resultante para que fiquem entre 0 e 255 e a imagem é retornada como float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sobel_derivative(img_channel: np.ndarray, kernel_size: int, kernel: np.ndarray) -> np.ndarray:\n",
    "    output = np.zeros(img_channel.shape)\n",
    "    kernel = np.flip(kernel, axis=(0,1))\n",
    "    pad_size = kernel_size // 2\n",
    "\n",
    "    padded_img = np.pad(img_channel.astype(np.float64), pad_size, mode='constant')\n",
    "    height, width = padded_img.shape\n",
    "\n",
    "    for i in range(pad_size, height - pad_size):\n",
    "        for j in range(pad_size, width - pad_size):\n",
    "            chunk = padded_img[i - pad_size:i + pad_size + 1, j - pad_size:j + pad_size + 1]\n",
    "            output[i - pad_size, j - pad_size] = np.sum(chunk * kernel)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_sobel_gradient(img_channel: np.ndarray, kernel_size: int, kernel_x: np.ndarray, kernel_y: np.ndarray) -> np.ndarray:\n",
    "    output = np.zeros(img_channel.shape)\n",
    "    kernel_x = np.flip(kernel_x, axis=(0,1))\n",
    "    kernel_y = np.flip(kernel_y, axis=(0,1))\n",
    "    pad_size = kernel_size // 2\n",
    "\n",
    "    padded_img = np.pad(img_channel.astype(np.float64), pad_size, mode='constant')\n",
    "    height, width = padded_img.shape\n",
    "\n",
    "    for i in range(pad_size, height - pad_size):\n",
    "        for j in range(pad_size, width - pad_size):\n",
    "            chunk = padded_img[i - pad_size:i + pad_size + 1, j - pad_size:j + pad_size + 1]\n",
    "            gx = np.sum(chunk * kernel_x)\n",
    "            gy = np.sum(chunk * kernel_y)\n",
    "            output[i - pad_size, j - pad_size] = np.sqrt(gx**2 + gy**2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/mine/building.ppm'\n",
    "img = read_ppm(img_path)\n",
    "bw_img = get_black_and_white(img)\n",
    "\n",
    "sobel_x_kernel = np.array([[-1, 0, 1], \n",
    "                           [-2, 0, 2], \n",
    "                           [-1, 0, 1]], dtype=np.float64)\n",
    "sobel_y_kernel = np.array([[-1, -2, -1], \n",
    "                           [ 0,  0,  0], \n",
    "                           [ 1,  2,  1]], dtype=np.float64)\n",
    "\n",
    "sobel_x = get_sobel_derivative(bw_img, 3, sobel_x_kernel)\n",
    "sobel_y = get_sobel_derivative(bw_img, 3, sobel_y_kernel)\n",
    "sobel_grad = get_sobel_gradient(bw_img, 3, sobel_x_kernel, sobel_y_kernel)\n",
    "\n",
    "show_images(bw_img, sobel_x, sobel_y, sobel_grad, titles=[\"original\", \"Sobel x\", \"Sobel y\", \"Gradient\"])\n",
    "\n",
    "save_ppm(sobel_x, 'sobel_x.ppm', '../output')\n",
    "save_ppm(sobel_y, 'sobel_y.ppm', '../output')\n",
    "save_ppm(sobel_grad, 'sobel_gradient.ppm', '../output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/mine/building.ppm'\n",
    "img = read_ppm(img_path)\n",
    "\n",
    "g = np.array([[1, 4, 7, 4, 1],\n",
    "              [4, 16, 26, 16, 4],\n",
    "              [7, 26, 41, 26, 7],\n",
    "              [4, 16, 26, 16, 4],\n",
    "              [1, 4, 7, 4, 1]], dtype=np.float64) / 273\n",
    "\n",
    "sobel_x_kernel = np.array([[-1, 0, 1], \n",
    "                           [-2, 0, 2], \n",
    "                           [-1, 0, 1]], dtype=np.float64)\n",
    "sobel_y_kernel = np.array([[-1, -2, -1], \n",
    "                           [ 0,  0,  0], \n",
    "                           [ 1,  2,  1]], dtype=np.float64)\n",
    "\n",
    "bw_img = get_black_and_white(img)\n",
    "sobel_x = get_sobel_derivative(bw_img, 3, sobel_x_kernel)\n",
    "sobel_y = get_sobel_derivative(bw_img, 3, sobel_y_kernel)\n",
    "sobel_grad = get_sobel_gradient(bw_img, 3, sobel_x_kernel, sobel_y_kernel)\n",
    "\n",
    "g_bw_image = filter_channel(bw_img, 5, g)\n",
    "g_sobel_x = get_sobel_derivative(g_bw_image, 3, sobel_x_kernel)\n",
    "g_sobel_y = get_sobel_derivative(g_bw_image, 3, sobel_y_kernel)\n",
    "g_sobel_grad = get_sobel_gradient(g_bw_image, 3, sobel_x_kernel, sobel_y_kernel)\n",
    "\n",
    "g_sobel_grad.shape\n",
    "\n",
    "images = [\n",
    "    bw_img, g_bw_image,\n",
    "    sobel_x, g_sobel_x,\n",
    "    sobel_y, g_sobel_y,\n",
    "    sobel_grad, g_sobel_grad\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"original\", \"Gaussian\",\n",
    "    \"Sobel x\", \"Gaussian Sobel x\",\n",
    "    \"Sobel y\",  \"Gaussian Sobel y\",\n",
    "    \"Gradient\", \"Gaussian Gradient\"\n",
    "]\n",
    "\n",
    "show_images(*images, titles=titles)\n",
    "\n",
    "save_ppm(g_sobel_x, 'gauss_sobel_x.ppm', '../output')\n",
    "save_ppm(g_sobel_y, 'gauss_sobel_y.ppm', '../output')\n",
    "save_ppm(g_sobel_grad, 'gauss_sobel_gradient.ppm', '../output')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/mine/flower.ppm'\n",
    "img = read_ppm(img_path)\n",
    "\n",
    "# Defaults tirados do exemplo https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html\n",
    "DEFAULT_T1 = 100\n",
    "DEFAULT_T2 = 200\n",
    "DEFAULT_APT = 3\n",
    "\n",
    "default = cv.Canny(img, DEFAULT_T1, DEFAULT_T2, apertureSize=DEFAULT_APT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise de apertureSize\n",
    "\n",
    "Como é possível ver abaixo, quanto maior é o apertureSize, mais sensível o filtro se torna a arestas. Ou seja, arestas de menor intensidade são identificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apertures = [5, 7]\n",
    "\n",
    "aperture_results = []\n",
    "aperture_titles = []\n",
    "for aperture in apertures:\n",
    "    aperture_results.append(cv.Canny(img, DEFAULT_T1, DEFAULT_T2, apertureSize=aperture))\n",
    "    aperture_titles.append(f\"aperture={aperture}\")\n",
    "\n",
    "show_images(img, default, *aperture_results, titles=[\"Original\", \"Default\", *aperture_titles], columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise de thresholds\n",
    "\n",
    "Threshold 1 (t1) e Threshold 2 (t2) servem para detectar se uma aresta vai ou não ser destacada. Se o valor da intensidade do gradiente em um ponto for maior que t2, essa aresta com certeza será destacada. Caso o valor da intensidade seja menor que t1, ela com certeza não será mostrada. Valores de intensidade entre os dois thresholds serão escolhidos com base na conectividade. Se uma aresta estão entre t1 e t2, mas está conectada a uma aresta acima de t2, então ela será marcada.\n",
    "\n",
    "Então, quando aumentamos tanto t1 quanto t2, observamos que a quantidade de arestas destacadas diminui. Entretanto, se aumentarmos de mais, corremos o risco de perder os detalhes relevantes da imagem, como ocorre abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deslizando a janela [t1, t2] para cima\n",
    "dts = [10, 50, 100, 200, 500] \n",
    "\n",
    "t1_results = []\n",
    "t1_titles = []\n",
    "for dt in dts:\n",
    "    t1_results.append(cv.Canny(img, DEFAULT_T1 + dt, DEFAULT_T2 + dt, apertureSize=DEFAULT_APT))\n",
    "    t1_titles.append(f\"dt={dt}\")\n",
    "\n",
    "show_images(img, default, *t1_results, titles=[\"Original\", \"Default\", *t1_titles], columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de analisar seria aumentar o tamanho janela, ao invés de deslizá-la. Nesse caso, aumentamos t2 (o limite máximo), o que impede arestas de baixo valor de intensidade do gradiente. Entretanto, diferente do caso anterior, damos mais chance a arestas que estão conectadas de se manterem. Assim, podemos manter um pouco mais de detalhe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentando o tamanho da jenala, ou seja, aumentamos apenas t2\n",
    "dts = [10, 50, 100, 200, 500] \n",
    "\n",
    "t1_results = []\n",
    "t1_titles = []\n",
    "for dt in dts:\n",
    "    t1_results.append(cv.Canny(img, DEFAULT_T1, DEFAULT_T1 + dt, apertureSize=DEFAULT_APT))\n",
    "    t1_titles.append(f\"dt={dt}\")\n",
    "\n",
    "show_images(img, default, *t1_results, titles=[\"Original\", \"Default\", *t1_titles], columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 7\n",
    "\n",
    "A partir do resultado abaixo, é possível ver que a redução de tamanho sem aplicação de filtro gera anomalias na imagem, especialmente nas menores. Por outro lado, quando aplicamos a função da biblioteca opencv que aplica um filtro gaussiano antes do downsize, o resultado é mais suave, ficando levemente borrado ao invés de uma imagem distorcida, ou seja, com aliasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyramid(images: list[np.ndarray]) -> np.ndarray:\n",
    "    height, width, _ = images[0].shape\n",
    "    canvas = np.zeros((height, width + width // 2, 3), dtype=np.uint8)\n",
    "\n",
    "    canvas[:height, :width] = images[0]\n",
    "\n",
    "    h_offset = 0\n",
    "    w_offset = width\n",
    "    for img in images[1:]:\n",
    "        h, w, _ = img.shape\n",
    "        # Aquele slice em img é necessário, pois as vezes ocorre uma diferença de\n",
    "        # 1 pixel no tamanho da imagem por conta da diminuição de tamanho.\n",
    "        canvas[h_offset:(h_offset + h), w_offset:(w_offset + w)] = img[:, :canvas.shape[1] - w_offset]\n",
    "        h_offset += h\n",
    "\n",
    "    return canvas\n",
    "\n",
    "def downsize_image_naive(image: np.ndarray, factor: int = 2) -> np.ndarray:\n",
    "    return image[::factor, ::factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/mine/chess.ppm'\n",
    "img = read_ppm(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols, _ = map(int, img.shape)\n",
    "aux_img = img.copy()\n",
    "downsize_naive = [aux_img.copy()]\n",
    "for i in range(3):\n",
    "    rows = (rows + 1) // 2\n",
    "    cols = (cols + 1) // 2\n",
    "    aux_img = downsize_image_naive(aux_img)\n",
    "    downsize_naive.append(aux_img.copy())\n",
    "\n",
    "rows, cols, _ = map(int, img.shape)\n",
    "aux_img = img.copy()\n",
    "downsize_gaussian = [aux_img.copy()]\n",
    "for i in range(3):\n",
    "    rows = (rows + 1) // 2\n",
    "    cols = (cols + 1) // 2\n",
    "    aux_img = cv.pyrDown(aux_img, (cols, rows))\n",
    "    downsize_gaussian.append(aux_img.copy())\n",
    "\n",
    "show_images(\n",
    "    create_pyramid(downsize_naive), \n",
    "    create_pyramid(downsize_gaussian), \n",
    "    titles=[\"Naive\", \"Gaussian\"],\n",
    "    columns=2,\n",
    "    scale=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 8\n",
    "\n",
    "Aplicando o upscaling com interpolação linear e bicúbica na imagem abaixo, podemos perceber um maior número de areas \"quadriculadas\" na imagem resultante da aplicação do filtro linear, enquanto a imagem resultante do filtro com interpolação bicubica possui regiões mais suaves, o que faz sentido já que a interpolação bicubica leva em consideração um número maior de pixels vizinhos.\n",
    "\n",
    "Abaixo foram mostrados o resultados para uma imagem pequena, (133, 133, 3), aumentada em 8 vezes. Os resultados foram apresentados dentro do próprio notebook. Entretanto, para comparar as imagens aumentadas em seus tamanhos reais, foi usado um visualizados de imagens com zoom em 100%. Um print da comparação foi inserida no notebook.\n",
    "\n",
    "![title](../images/lista1_q10.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../ppm_images/tree_1.ppm'\n",
    "img = read_ppm(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "height, width, _ = img.shape\n",
    "factor = 8\n",
    "\n",
    "linear = cv.resize(img, (width * factor, height * factor), interpolation = cv.INTER_LINEAR)\n",
    "bicubic = cv.resize(img, (width * factor, height * factor), interpolation = cv.INTER_CUBIC)\n",
    "\n",
    "show_images(linear, bicubic, titles=[\"Inter. Linear\", \"Inter. Bicúbica\"], scale=9)\n",
    "show_image(linear, title=\"Inter. Linear\")\n",
    "show_image(bicubic, title=\"Inter. Bicúbica\")\n",
    "\n",
    "print(f\"linear = {linear.shape}\")\n",
    "print(f\"bicubic = {bicubic.shape}\")\n",
    "\n",
    "save_ppm(linear, 'resize_linear.ppm', '../output')\n",
    "save_ppm(bicubic, 'resize_bicubic.ppm', '../output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
